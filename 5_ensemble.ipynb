{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:47:10.305950Z",
     "start_time": "2025-05-10T09:47:08.219891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, roc_auc_score, \\\n",
    "    accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def drop_empty_items(data_frame: DataFrame) -> DataFrame:\n",
    "    data_frame = data_frame.drop(['Insulin'], axis=1)\n",
    "    return data_frame[(data_frame['Glucose'] != 0) & (data_frame['BloodPressure'] != 0) & (data_frame['BMI'] != 0)]\n",
    "\n",
    "\n",
    "def scale_features(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def print_score(y_test, y_pred) -> None:\n",
    "    # Calculate other evaluation metrics for test set\n",
    "    print(f\"SIMPLE XGBoost\")\n",
    "    print(\"===========================================================================\")\n",
    "    print(\"\\nClassification Report:\\n\",\n",
    "          classification_report(y_test, y_pred, target_names=['non-diabetic', 'diabetic']))\n",
    "    print(\"XGBoost Model Evaluation:\")\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(f\"Precision (Weighted): {precision:.6f}\")\n",
    "    print(f\"Recall (Weighted): {recall:.6f}\")\n",
    "    print(f\"F1-Score (Weighted): {f1:.6f}\")\n",
    "\n",
    "    print(\"Class distribution before SMOTE:\", y_train.value_counts().to_dict())\n",
    "    print(\"Class distribution after SMOTE:\", pd.Series(y_train_smote).value_counts().to_dict())\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"ROC-AUC: {roc_auc:.6f}\")\n",
    "\n",
    "    # Print confusion matrix with class labels\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_names = ['non-diabetic', 'diabetic']\n",
    "    print(\"\\nConfusion Matrix with Class Labels:\")\n",
    "    print(pd.DataFrame(conf_matrix, index=class_names, columns=class_names))\n",
    "\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    print(\"Specificity: \", specificity)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    print(\"Sensitivity: \", sensitivity)"
   ],
   "id": "c1db36d48ac16c81",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:52:51.573809Z",
     "start_time": "2025-05-10T09:52:07.501720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Load the PIMA dataset\n",
    "df = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Step 1: Remove rows with zero values in 'Glucose', 'BloodPressure', or 'BMI'\n",
    "df = drop_empty_items(df)\n",
    "\n",
    "# Define features\n",
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'BMI',\n",
    "            'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "# Splitting dataset into 80-20 split\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features after split (Z-scores, deviation from paper to avoid leakage)\n",
    "X_train, X_test = scale_features(X_train, X_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define individual models and their hyperparameter grids (from Table 3)\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'subsample': [0.8, 1]\n",
    "}\n",
    "\n",
    "# MLP\n",
    "mlp = MLPClassifier(random_state=42, max_iter=2000, solver='adam')\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(50, 50)],\n",
    "    'alpha': [0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform grid search for each model\n",
    "models = [\n",
    "    ('rf', rf, rf_param_grid),\n",
    "    ('xgb', xgb, xgb_param_grid),\n",
    "    ('mlp', mlp, mlp_param_grid),\n",
    "    ('gb', gb, gb_param_grid)\n",
    "]\n",
    "\n",
    "best_estimators = {}\n",
    "for name, model, param_grid in models:\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='f1_weighted',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid_search.fit(X_train_smote, y_train_smote)\n",
    "    best_estimators[name] = grid_search.best_estimator_\n",
    "    print(f\"Best {name} Hyperparameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best {name} F1-Weighted Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Create ensemble model with soft voting\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', best_estimators['rf']),\n",
    "        ('xgb', best_estimators['xgb']),\n",
    "        ('mlp', best_estimators['mlp']),\n",
    "        ('gb', best_estimators['gb'])\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[2, 1, 1, 1]\n",
    ")\n",
    "\n",
    "# Train ensemble on SMOTE-balanced training data\n",
    "print(\"\\nTraining ensemble model...\")\n",
    "ensemble.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Evaluate ensemble on test set\n",
    "y_pred = ensemble.predict(X_test)\n",
    "print_score(y_test, y_pred)"
   ],
   "id": "789230fcb79e2d97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning rf...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best rf Hyperparameters: {'bootstrap': False, 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best rf F1-Weighted Score: 0.8094\n",
      "\n",
      "Tuning xgb...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best xgb Hyperparameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Best xgb F1-Weighted Score: 0.7996\n",
      "\n",
      "Tuning mlp...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best mlp Hyperparameters: {'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'learning_rate_init': 0.001}\n",
      "Best mlp F1-Weighted Score: 0.8204\n",
      "\n",
      "Tuning gb...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best gb Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Best gb F1-Weighted Score: 0.7978\n",
      "\n",
      "Training ensemble model...\n",
      "SIMPLE XGBoost\n",
      "===========================================================================\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-diabetic       0.88      0.81      0.85       102\n",
      "    diabetic       0.63      0.74      0.68        43\n",
      "\n",
      "    accuracy                           0.79       145\n",
      "   macro avg       0.76      0.78      0.76       145\n",
      "weighted avg       0.81      0.79      0.80       145\n",
      "\n",
      "XGBoost Model Evaluation:\n",
      "Accuracy:  0.7931034482758621\n",
      "Precision (Weighted): 0.807202\n",
      "Recall (Weighted): 0.793103\n",
      "F1-Score (Weighted): 0.797685\n",
      "Class distribution before SMOTE: {0: 373, 1: 206}\n",
      "Class distribution after SMOTE: {0: 373, 1: 373}\n",
      "ROC-AUC: 0.778956\n",
      "\n",
      "Confusion Matrix with Class Labels:\n",
      "              non-diabetic  diabetic\n",
      "non-diabetic            83        19\n",
      "diabetic                11        32\n",
      "Specificity:  0.8137254901960784\n",
      "Sensitivity:  0.7441860465116279\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
